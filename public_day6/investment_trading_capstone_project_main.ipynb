{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investment and Trading Capstone Project\n",
    "## Build a Stock Price Indicator\n",
    "\n",
    "## 1. Introduction\n",
    "Financial institutions around the world are trading in billions of dollars on a daily basis. Investment firms, hedge funds and even individuals have been using financial models to better understand market behavior and make profitable investments and trades.  A wealth of information is available in the form of historical stock prices and company performance data, suitable for machine learning algorithms to process.\n",
    "\n",
    "In this project, I will be building a stock price predictor that takes daily trading data over a certain date range as input, and outputs projected estimates for given query dates. Note that the inputs will contain multiple metrics, such as opening price (Open), highest price the stock traded at (High), how many stocks were traded (Volume) and closing price adjusted for stock splits and dividends (Adjusted Close); I will be predicting the Adjusted Close price."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install and import relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is the colab code: https://colab.research.google.com/drive/1Xhcgrryu1a9eknPVIM3r0QAHUDW8_Zwn?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#from pandas_datareader.data import DataReader\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from IPython import display\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "#import functions\n",
    "#import plotting\n",
    "\n",
    "from datetime import datetime,date\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.metrics import mean_squared_error\n",
    "from keras.layers import LSTM\n",
    "\n",
    "# Needed to help our plots look cleaner with plotly \n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "from plotly import tools\n",
    "init_notebook_mode(connected=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploratory Analysis\n",
    "In this section we would be getting the data, view the data and compute some statistics and plots to understand the data very well before we start the modelling process.\n",
    "### Getting the Data\n",
    "The data I will be using for the project is from [yahoo finance](https://finance.yahoo.com/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/free-stock-data-for-python-using-yahoo-finance-api-9dafd96cad2e\n",
    "# https://www.learndatasci.com/tutorials/python-finance-part-yahoo-finance-api-pandas-matplotlib/\n",
    "\n",
    "# Install yfinance\n",
    "#!pip install yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download stock data then export as CSV\n",
    "\n",
    "import yfinance as yfin\n",
    "\n",
    "#tickes are S&P 500, Apple, Microsoft, Amazon, Johnson & Johnson, Pfizer, Ford and Google\n",
    "tickers = (\"SPY\", \"AAPL\", \"MSFT\", \"AMZN\", \"F\", \"GOOGL\") \n",
    "\n",
    "start = \"2001-01-01\"\n",
    "end = '2021-08-17'\n",
    "\n",
    "fin_data = yfin.download(tickers, start, end) #download yahoo finance data for specific dates\n",
    "\n",
    "fin_data.to_csv('fin_data.csv') #convert data to csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the dimensions of the data\n",
    "fin_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#view the first 5 rows of the data\n",
    "fin_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#view the last 5 values of the data\n",
    "fin_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if there are missing values for each type of stock\n",
    "fin_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Google has some missing values, and we will use the `fillna` method to resolve the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handing missing values\n",
    "fin_data.fillna(method='ffill', inplace = True) # use front fill method\n",
    "fin_data.fillna(method='bfill', inplace = True) # use back fill method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check to see if there are still any missing values\n",
    "fin_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we have no missing values. We will now check some descriptive statistics of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#view descriptive statistics of adjusted close process of the stocks\n",
    "fin_data[['Adj Close']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view general info\n",
    "fin_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the maximum close date of stocks\n",
    "def max_close(stocks,df):\n",
    "    \"\"\" This calculates and returns the maximum closing value of a specific stock\"\"\"\n",
    "    return df['Close'][stocks].max() # computes and returns the maximum closing stock value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the above function with specific stocks\n",
    "def test_max():\n",
    "    \"\"\" This tests the max_close function\"\"\"\n",
    "    for stocks in [\"SPY\", \"AAPL\", \"MSFT\", \"AMZN\", \"F\", \"GOOGL\"]:\n",
    "        print(\"Maxiumum Closing Value for {} is {}\".format(stocks, max_close(stocks,fin_data)))\n",
    "\n",
    "test_max()        \n",
    "#if __name__ == \"__main__\" :\n",
    "#    test_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the mean volume for the stocks\n",
    "def mean_vol(stocks,df):\n",
    "    \"\"\" This calculates and returns the minimum volume of a specific stock\"\"\"\n",
    "    return df['Volume'][stocks].mean() # computes and returns the minimum volume of a stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the above function with specific stocks\n",
    "def test_mean():\n",
    "    \"\"\" This tests the max_close function\"\"\"\n",
    "    for stocks in [\"SPY\", \"AAPL\", \"MSFT\", \"AMZN\", \"F\", \"GOOGL\"]:\n",
    "        print(\"Mean Volume for {} is {}\".format(stocks, mean_vol(stocks,fin_data)))\n",
    "\n",
    "test_mean()        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting stock prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot function for the Adjusted closing value\n",
    "def plot_adj(df,title,stocks,y=0):\n",
    "        ax = df['Adj Close'][stocks].plot(title=title, figsize=(16,8), ax=None)\n",
    "        ax.set_xlabel(\"Date\")\n",
    "        ax.set_ylabel(\"Stock Price\")\n",
    "        ax.axhline(y=y,color='black')\n",
    "        ax.legend(stocks, loc='upper left')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the plot of Adjusted close\n",
    "stocks = [\"SPY\", \"AAPL\", \"MSFT\", \"AMZN\",  \"F\", \"GOOGL\"]\n",
    "plot_adj(fin_data,\"Adjusted Close Stock Prices\",stocks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plot above, we can see that Amazon and Google has the highest growth. This could be as a result of the increase in useage of these companies world wide, but let us normalize the data before we make that conclusion. I will explore more features in the dataset before normalizing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot function for the High prices\n",
    "def plot_high(df,title,stocks,y=0):\n",
    "        ax = df['High'][stocks].plot(title=title, figsize=(16,8), ax = None)\n",
    "        ax.set_xlabel(\"Date\")\n",
    "        ax.set_ylabel(\"Stock Price\")\n",
    "        ax.axhline(y=y,color='black')\n",
    "        ax.legend(stocks, loc='upper left')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the plot of high stock prices\n",
    "stocks = [\"SPY\", \"AAPL\", \"MSFT\", \"AMZN\",  \"F\", \"GOOGL\"]\n",
    "title = \"High Stock Prices\"\n",
    "plot_high(fin_data,title,stocks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the adjusted value plot, we can see high stock prices for Amazon and Google. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#view only google Adjusted close price\n",
    "fin_data['Adj Close']['GOOGL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view only google and amazon Adjusted close price\n",
    "fin_data['Adj Close'][['GOOGL', 'AMZN']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view all stocks adjusted close prices for amazon and google from Jan 2010 to Aug 2021\n",
    "fin_data['Adj Close'].loc['2010-01-01':'2021-08-17', ['AMZN', 'GOOGL']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to plot data\n",
    "def plot_data1(df,stocks,title,ylabel='Stock Price',y=0):\n",
    "    \"\"\"This funtion plots stock prices\"\"\"\n",
    "    ax = df.plot(title=title, figsize=(16,8), ax=None, fontsize=2)\n",
    "    ax.set_xlabel(\"Date\")\n",
    "    ax.set_label(ylabel)\n",
    "    ax.axhline(y=y,color='black')\n",
    "    ax.legend(stocks, loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to plot selected stocks\n",
    "def selected_plot(df, columns,stocks, start_idx, end_idx):\n",
    "    \"\"\"This function plots specific stocks over a given date range\"\"\"\n",
    "    plot_data1(df[columns].loc[start_idx:end_idx, stocks],stocks, title=\"Plot for selected Stocks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to plot data based on specific columns, symbols, and date ranges\n",
    "def test_select():\n",
    "    \"\"\"This function plots stock data based on specific columns, symbols, and date ranges \"\"\"\n",
    "    # specify columns to plot and stock symbols\n",
    "    columns = 'Adj Close'\n",
    "    stocks = ['GOOGL', 'AMZN']  \n",
    "        \n",
    "    # Get stock data\n",
    "    df = fin_data\n",
    "\n",
    "    # Slice and plot\n",
    "    selected_plot(df, columns, stocks, '2010-01-01', '2021-08-17')\n",
    "    \n",
    "test_select()  # run the plot function  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing the data\n",
    "We want to know how the different types of stocks went up and down with respect to the others. In order to do this, we will normalize the data. We do this by dividing the values of each column by day one to ensure that each stock starts with ${$1}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data2(df,stocks,title='Stock Prices',ylabel=\"Stock Price\",y=0, start='2001-01-01', end ='2021-08-17'):\n",
    "    \n",
    "    \"\"\" This function creates a plot of adjusted close stock prices\n",
    "    inputs:\n",
    "    df - dataframe\n",
    "    title - plot title\n",
    "    stocks - the stock symbols of each company\n",
    "    ylabel - y axis label\n",
    "    y - horizontal line(integer)\n",
    "    output: the plot of adjusted close stock prices\n",
    "    \"\"\"\n",
    "    df_new = df[start:end]\n",
    "    #ax = df_new['Adj Close'][stocks].plot(title=title, figsize=(16,8), ax = None)\n",
    "    ax = df_new.plot(title=title, figsize=(16,8), ax = None)\n",
    "    ax.set_xlabel(\"Date\")\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.axhline(y=y,color='black')\n",
    "    ax.legend(stocks, loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function that normalizes the data\n",
    "def normalize_data(df):\n",
    "    \"\"\" \n",
    "    This function normalizes the stock prices using the first row of the dataframe\n",
    "    input - stock data\n",
    "    output - normalized stock data\n",
    "    \"\"\"\n",
    "    return df/df.iloc[0,:]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the data with the new normalized data\n",
    "\n",
    "stocks = [\"SPY\", \"AAPL\", \"MSFT\", \"AMZN\", \"F\", \"GOOGL\"]\n",
    "\n",
    "plot_data2(normalize_data(fin_data['Adj Close'][stocks]),stocks,title = \"Normalized Stock Prices\", ylabel = 'Cummulative return',y=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above cummulative return plot, we can see that Apple has the highest return over the years, while Amazon was second and Google third and Microsoft fourth. The growth of Google and Microsoft looks much more stable than Apple and Amazon. Looking at the plot, Apple has alot of volatility and risky stocks especially in recent years."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cumulative Return\n",
    "Let's have a look at how the pandemic affected stock prices for these companies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks = [\"SPY\", \"AAPL\", \"MSFT\", \"AMZN\", \"F\", \"GOOGL\"]\n",
    "\n",
    "plot_data2(normalize_data(fin_data['Adj Close'][stocks]['2019-01-01':'2019-12-31']), stocks,title = '2019', ylabel = 'Cummulative return',y=1, start='2019-01-01', end = '2019-12-31') #2019\n",
    "plot_data2(normalize_data(fin_data['Adj Close'][stocks]['2020-01-01':'2020-12-31']), stocks,title = '2020', ylabel = 'Cummulative return',y=1, start='2020-01-01', end = '2020-12-31') #2020\n",
    "plot_data2(normalize_data(fin_data['Adj Close'][stocks]['2021-01-01':'2021-08-17']), stocks,title = '2021', ylabel = 'Cummulative return',y=1, start='2021-01-01', end = '2021-08-17') #2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above plots, let's take note of the following:\n",
    "\n",
    "    1. 2019: Before the pandemic, we notice that most of the companies stocks were doing relatively well with Apple and Microsoft taking the lead and Pfizer trailing behind.\n",
    "    2. 2020: On the onset of the pandemic around Spring, we notice that there was a fall in stock prices for all the companies, but afterwards the technology companies like Amazon, Apple, Microsoft and Google started to grow again. But companies like Pfizer, Ford and S&P 500 did not do very well especially Ford.\n",
    "    3. 2021: As the vaccine rollout began and the lockdown began to be lifted, we can see significant growth in the stock prices of Ford in particular given that its stock prices which were low in 2020 due to the pandemic. Companies like Google and Microsoft and S&P 500 also grew. Overall there was an improvement in the stock prices of all the companies we considered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the Rolling mean and Bollinger Bands\n",
    "The rolling mean may give us some idea about the true underlying prices of a stock. If there is a significant deviation below or above the rolling mean, it may give us an idea about a potential buying and selling opportunity respectively. The challenge remains to know when this deviation is significant enough to pay attention to it. [Bollinger Bands](https://en.wikipedia.org/wiki/Bollinger_Bands) is a statistical chart that contains the volatility of a financial instrument over time. `Bollinger` observed that looking at the recent volatility of the stock, if it is very volatile, we might discard the movement above and below the mean. But if it is not very volatile we may want to pay attention to it. He added a band  $2\\delta$ (2 standard deviations)  above and below the mean. We would use the rolling standard deviation to help us achieve this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute rolling mean, rolling standard deviation, upper and lower bands\n",
    "\n",
    "def rolling_stats(df, stocks, type_, window = 20):\n",
    "    \"\"\"\n",
    "    This function computes the rolling mean and Bollinger bands\n",
    "    inputs : \n",
    "    df - dataframe\n",
    "    stocks - the type of stocks we would be analyzing\n",
    "    type_ - the price type of the rolling calculation\n",
    "    window - number of days used to calculate the statistics\n",
    "    output: \n",
    "    rolling mean, rolling standard deviation, upper and lower bands of 2 std each\n",
    "    \"\"\"\n",
    "    \n",
    "    val = df[(type_,stocks)]\n",
    "    rolling_mean = df[(type_, stocks)].rolling(window=window).mean()\n",
    "    rolling_std = df[(type_, stocks)].rolling(window=window).std()\n",
    "    upper_band = rolling_mean + rolling_std*2\n",
    "    lower_band = rolling_mean - rolling_std*2\n",
    "    \n",
    "    return val, rolling_mean, rolling_std, upper_band, lower_band\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the rolling mean, rolling standard deviation, upper and lower bands\n",
    "\n",
    "def rolling_plot(stocks, val, rolling_mean, upper_band, lower_band, title='Rolling mean'):\n",
    "    \"\"\"\n",
    "    This function plots the rolling mean and Bollinger bands\n",
    "    inputs : \n",
    "    stocks - the type of stocks we would be analyzing\n",
    "    val - value of the stock price type\n",
    "    rolling_mean - rolling mean\n",
    "    upper_band - stocks upper band\n",
    "    lower_band - stocks lower band\n",
    "    title - plot title\n",
    "    output: \n",
    "    plot of rolling mean, rolling standard deviation, upper and lower bands of 2 std each\n",
    "    \"\"\"\n",
    "    \n",
    "    ax = rolling_mean.plot(title=title, figsize=(16,8), label='Rolling Mean')\n",
    "    plt.plot(upper_band, label = 'Upper Band')\n",
    "    plt.plot(lower_band, label = 'Lower Band')\n",
    "    plt.plot(val, label = 'Value of Stock')\n",
    "    ax.set_xlabel('Date')\n",
    "    ax.set_ylabel('Price')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "    return ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks = 'MSFT'\n",
    "type_ = 'Adj Close'\n",
    "\n",
    "val, rolling_mean, rolling_std, upper_band, lower_band = rolling_stats(fin_data['2019-01-01':'2021-08-17'], stocks, type_)\n",
    "\n",
    "rolling_plot(stocks, val, rolling_mean, upper_band, lower_band, title='Rolling mean of {} for {} 20 days window'.format(type_,stocks))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view rolling statistics for Apple\n",
    "stocks = 'AAPL'\n",
    "type_ = 'Adj Close'\n",
    "\n",
    "val, rolling_mean, rolling_std, upper_band, lower_band = rolling_stats(fin_data['2019-01-01':'2021-08-17'], stocks, type_)\n",
    "\n",
    "rolling_plot(stocks, val, rolling_mean, upper_band, lower_band, title='Rolling mean of {} for {} 20 days window'.format(type_,stocks))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view rolling statistics for Ford\n",
    "stocks = 'F'\n",
    "type_ = 'Adj Close'\n",
    "\n",
    "val, rolling_mean, rolling_std, upper_band, lower_band = rolling_stats(fin_data['2019-01-01':'2021-08-17'], stocks, type_)\n",
    "\n",
    "rolling_plot(stocks, val, rolling_mean, upper_band, lower_band, title='Rolling mean of {} for {} 20 days window'.format(type_,stocks))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above plots, we can see that the initial values for the rolling mean are missing. This is as a result of the 20 days window period we used at the beginning which had no values. We can also observe that the rolling mean follows the movement of the raw stock prices and it is less spiky. We can also see that Ford has lower stock prices than Microsoft and Apple in 2020. In this data exploration session, I only considered a 20 days window and for 2 standard deviation away from the mean for simplicity. You may want to try computing different windows sizes and standard deviations to see how differently the stock prices behave."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing Daily Returns\n",
    "Daily returns tells us how much the stock price go up and down on a particular day. We can compute using the following function\n",
    "$$\n",
    "DailyReturn = \\frac{price(t)}{price(t-1)} -1\n",
    "$$\n",
    "where `price(t)` is the price of today's stock and `price(t-1)` is the price of yesterday's stock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def daily_returns_cal(df,stocks):\n",
    "    \"\"\"\n",
    "    This function computes and returns the daily return values\n",
    "    input: df (dataframe) and stocks\n",
    "    output: daily return values\n",
    "    \"\"\"\n",
    "    \n",
    "    daily_returns = (df[('Adj Close', stocks)][1:]/df[('Adj Close', stocks)][:-1].values) - 1\n",
    "       \n",
    "    return daily_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily return of Microsoft\n",
    "plot_data2(daily_returns_cal(fin_data,'MSFT'),stocks=['MSFT'], ylabel = 'Daily returns',title='Stock Prices for Microsoft',y=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily return of Ford\n",
    "plot_data2(daily_returns_cal(fin_data,'F'),stocks=['F'], ylabel = 'Daily returns',title='Stock Prices for Ford',y=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above plots, we can see that the volatility range for Ford is higher than Microsoft. This could be as a result of technology companies like Microsoft bouncing back faster during the pandemic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Modelling\n",
    "In this section I will be trying out some models to predict the Adjusted closing price of a stock."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting Adjusted close value of Microsoft stocks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that get specific stock data and fills in any missing value\n",
    "def get_data(df, stocks):\n",
    "    \"\"\"\n",
    "    This function gets a specific stock data and fills in any missing values using the fill forward and fill backward methods\n",
    "    Input: \n",
    "    df - dataframe\n",
    "    stocks - the type of stock\n",
    "    Output - a cleaned dataset to be used for prediction\n",
    "    \"\"\"\n",
    "    df1 = pd.DataFrame (data = df.iloc[:, df.columns.get_level_values(1)==stocks].values,\n",
    "                          index = df.iloc[:, df.columns.get_level_values(1)==stocks].index,\n",
    "                          columns = df.iloc[:, df.columns.get_level_values(1)==stocks].columns.get_level_values(0))\n",
    "    \n",
    "    df1.fillna(method='ffill', inplace= True)\n",
    "    df1.fillna(method='bfill', inplace=True)\n",
    "    \n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get Microsoft data and view the first 5 rows\n",
    "msft_data = get_data(fin_data, 'MSFT')  \n",
    "msft_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot showing Microsoft historical Adjusted closing prices\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.title('Microsoft Adjusted Close Price History')\n",
    "plt.plot(msft_data['Adj Close'])\n",
    "plt.xlabel('Date', fontsize=18)\n",
    "plt.ylabel('Adjusted Close Price USD ($)', fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting using Long Short-Term Memory (LSTM) \n",
    "[LSTM](https://en.wikipedia.org/wiki/Long_short-term_memory#:~:text=Long%20short%2Dterm%20memory%20(LSTM)%20is%20an%20artificial%20recurrent,networks%2C%20LSTM%20has%20feedback%20connections.&text=A%20common%20LSTM%20unit%20is,gate%20and%20a%20forget%20gate.) is an artificial recurrent neural network (RNN) architecture used in deep learning that is capable of learning long-term dependencies. It processes data passing on information as it propagates forward and have a chain like structure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#view the shape\n",
    "msft_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the variables for prediction and split into training and test sets\n",
    "\n",
    "y = np.log(msft_data['Adj Close'].astype(int)) # we want to predict the adjusted close price\n",
    "X = msft_data.drop('Adj Close', axis=1) # predictive variables (removing Adj close from it)\n",
    "\n",
    "#split the data into training and test sets\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the LSTM model for Microsoft stock\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, return_sequences=True, input_shape= (xtrain.shape[1], 1)))\n",
    "model.add(LSTM(64, return_sequences=False))\n",
    "model.add(Dense(25))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial parameters used for LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model - part 1\n",
    "model.fit(np.array(xtrain).reshape(-1,5,1), ytrain, batch_size =1, epochs=5, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions \n",
    "predictions = model.predict(np.array(xtest).reshape(-1,5,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculation of the mean absolute error\n",
    "mean_abs_error3 = mean_absolute_error(ytest, predictions)\n",
    "mean_abs_error3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model - part 2\n",
    "model.fit(np.array(xtrain).reshape(-1,5,1), ytrain, batch_size =100, epochs=10, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions 2\n",
    "predictions = model.predict(np.array(xtest).reshape(-1,5,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculation of the mean absolute error 2\n",
    "mean_abs_error3 = mean_absolute_error(ytest, predictions)\n",
    "mean_abs_error3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Refinement\n",
    "#### Final Parameters used to tune LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the LSTM model with the relu activation function\n",
    "model2 = Sequential()\n",
    "model2.add(LSTM(128, activation='relu', return_sequences=True, input_shape= (xtrain.shape[1], 1)))\n",
    "model2.add(LSTM(64, activation='relu', return_sequences=False))\n",
    "model2.add(Dense(25))\n",
    "model2.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model2.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view model2 summary\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model - part 3\n",
    "model2.fit(np.array(xtrain).reshape(-1,5,1), ytrain, batch_size =1, epochs=5, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions 3\n",
    "predictions2 = model2.predict(np.array(xtest).reshape(-1,5,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculation of the mean absolute error 2\n",
    "mean_abs_error2 = mean_absolute_error(ytest, predictions)\n",
    "mean_abs_error2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model - part 4 (increasing no. of epochs and batch_size)\n",
    "model2.fit(np.array(xtrain).reshape(-1,5,1), ytrain, batch_size =100, epochs=10, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions 3\n",
    "predictions2 = model2.predict(np.array(xtest).reshape(-1,5,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculation of the mean absolute error 2\n",
    "mean_abs_error2 = mean_absolute_error(ytest, predictions)\n",
    "mean_abs_error2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot showing the prediction and actual values\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(24, 10), dpi=80)\n",
    "axs[0].set_title('Predicted vs actual values distribution')\n",
    "ax1 = sns.kdeplot(data=ytest, color=\"g\", label='Actual values',ax=axs[0])\n",
    "ax2 = sns.kdeplot(data=predictions2, color=\"b\", label='Predicted values', ax=ax1)\n",
    "    \n",
    "sns.regplot(x=ytest, y=predictions2)\n",
    "plt.title('Predicted vs actual values distribution')\n",
    "plt.xlabel('Stock Price')\n",
    "#plt.legend()\n",
    "ax1.legend()\n",
    "plt.show()\n",
    "plt.close()\n",
    "    \n",
    "print(\"Mean absolute error of {0}: {1}\".format(model,mean_abs_error3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model part 5 (no activation function)\n",
    "model.fit(np.array(xtrain).reshape(-1,5,1), ytrain, batch_size =800, epochs=50, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions \n",
    "predictions = model.predict(np.array(xtest).reshape(-1,5,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculation of the mean absolute error\n",
    "mean_abs_error3 = mean_absolute_error(ytest, predictions)\n",
    "mean_abs_error3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot showing the prediction and actual values\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(24, 10), dpi=80)\n",
    "axs[0].set_title('Predicted vs actual values distribution')\n",
    "ax1 = sns.kdeplot(data=ytest, color=\"g\", label='Actual values',ax=axs[0])\n",
    "ax2 = sns.kdeplot(data=predictions, color=\"b\", label='Predicted values', ax=ax1)\n",
    "    \n",
    "sns.regplot(x=ytest, y=predictions)\n",
    "plt.title('Predicted vs actual values distribution')\n",
    "plt.xlabel('Stock Price')\n",
    "#plt.legend()\n",
    "ax1.legend()\n",
    "plt.show()\n",
    "plt.close()\n",
    "    \n",
    "print(\"Mean absolute error of {0}: {1}\".format(model,mean_abs_error3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above, we can see that the model is trained and evaluated using `LSTM`. The predicted and actual adjustable stock prices plots look are relatively similar with a mean absolute error of 0.0591 which isn't bad. However, there is still room for improvement and trying out other models to compare."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting using Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#view the shape\n",
    "msft_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the model for Adj close prediction\n",
    "\n",
    "y = np.log(msft_data['Adj Close'].astype(int)) # we want to predict the adjusted close price\n",
    "X = msft_data.drop('Adj Close', axis=1) # predictive variables (removing Adj close from it)\n",
    "\n",
    "#split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "print(\"x_train\", X_train.shape)\n",
    "print(\"y_train\", y_train.shape)\n",
    "print(\"x_test\", X_test.shape)\n",
    "print(\"y_test\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating an instance of a Linear Regressor \n",
    "model_lin = LinearRegression()\n",
    "\n",
    "#fit the model\n",
    "model_lin.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the score, coef_ and intercept_ of the model\n",
    "model_lin.score(X_train,y_train)\n",
    "model_lin.coef_\n",
    "model_lin.intercept_\n",
    "\n",
    "print('The score of the model is {}, the coeficients  are {} and the intercept is {}'.format(model_lin.score(X_train,y_train),model_lin.coef_,model_lin.intercept_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction\n",
    "predict = model_lin.predict(X_test)\n",
    "predict #view some predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculation of the mean absolute error\n",
    "mean_abs_error = mean_absolute_error(y_test, predict)\n",
    "mean_abs_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot showing the prediction and actual values\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(24, 10), dpi=80)\n",
    "axs[0].set_title('Predicted vs actual values distribution')\n",
    "ax1 = sns.kdeplot(data=y_test, color=\"g\", label='Actual values',ax=axs[0])\n",
    "ax2 = sns.kdeplot(data=predict, color=\"b\", label='Predicted values', ax=ax1)\n",
    "    \n",
    "sns.regplot(x=y_test, y=predict)\n",
    "plt.title('Predicted vs actual values distribution')\n",
    "plt.xlabel('Stock Price')\n",
    "#plt.legend()\n",
    "ax1.legend()\n",
    "plt.show()\n",
    "plt.close()\n",
    "    \n",
    "print(\"Mean absolute error of {0}: {1}\".format(model_lin,mean_abs_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above, we can see that the model is trained and evaluated using `LinearRegression`. The predicted and actual adjustable stock prices plots have variations but with a mean absolute error is 0.215 which abit worst than the LSTM model. However, there is still room for improvement and trying out other models to compare. Let't try out another model and see how it performs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting  using Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the model for Adj close prediction\n",
    "\n",
    "y = np.log(msft_data['Adj Close'].astype(int)) # we want to predict the adjusted close price\n",
    "X = msft_data.drop('Adj Close', axis=1) # predictive variables (removing Adj close from it)\n",
    "\n",
    "#split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "print(\"x_train\", X_train.shape)\n",
    "print(\"y_train\", y_train.shape)\n",
    "print(\"x_test\", X_test.shape)\n",
    "print(\"y_test\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating an instance of a Random Forest Regressor \n",
    "model_rf = RandomForestRegressor(n_estimators=100, random_state=47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit the model with the training data\n",
    "model_rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction\n",
    "predict = model_rf.predict(X_test)\n",
    "predict #view some predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculation of the mean absolute error\n",
    "mean_abs_error = mean_absolute_error(y_test, predict)\n",
    "mean_abs_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view predictions and actual values\n",
    "#print(np.c_[y_test,predict])\n",
    "display_ = pd.DataFrame({'Actual value': y_test, 'Predicted value':predict})\n",
    "display_.head(10)\n",
    "#print(y_test,predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the table, we can see that the `RandomForestRegressor` performed very well and the actual and predicted Adjusted close value are fairly close. Let us now view the plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot showing the prediction and actual values\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(24, 10), dpi=80)\n",
    "axs[0].set_title('Predicted vs actual values distribution')\n",
    "ax1 = sns.kdeplot(data=y_test, color=\"g\", label='Actual values',ax=axs[0])\n",
    "ax2 = sns.kdeplot(data=predict, color=\"b\", label='Predicted values', ax=ax1)\n",
    "    \n",
    "sns.regplot(x=y_test, y=predict)\n",
    "plt.title('Predicted vs actual values distribution')\n",
    "plt.xlabel('Stock Price')\n",
    "#plt.legend()\n",
    "ax1.legend()\n",
    "plt.show()\n",
    "plt.close()\n",
    "    \n",
    "print(\"Mean absolute error of {0}: {1}\".format(model_rf,mean_abs_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above, we can see that the model is trained and evaluated using `RandomForestRegressor`. The predicted and actual adjustable stock prices plots look are relatively similar with a mean absolute error is 0.0494 which is good. Let us see how our three models would perfomr with the Google stocks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting Adjusted close value of Google stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get Google data and view the first 5 rows\n",
    "googl_data = get_data(fin_data, 'GOOGL')  \n",
    "googl_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot showing Google historical Adjusted closing prices\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.title('Google Adjusted Close Price History')\n",
    "plt.plot(googl_data['Adj Close'])\n",
    "plt.xlabel('Date', fontsize=18)\n",
    "plt.ylabel('Adjusted Close Price USD ($)', fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the model for Adj close prediction\n",
    "\n",
    "# create the variables for prediction and split into training and test sets\n",
    "\n",
    "y = np.log(googl_data['Adj Close'].astype(int)) # we want to predict the adjusted close price\n",
    "X = googl_data.drop('Adj Close', axis=1) # predictive variables (removing Adj close from it)\n",
    "\n",
    "#split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "print(\"x_train\", X_train.shape)\n",
    "print(\"y_train\", y_train.shape)\n",
    "print(\"x_test\", X_test.shape)\n",
    "print(\"y_test\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction Using LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### LSTM Model for Google stocks\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, return_sequences=True, input_shape= (X_train.shape[1], 1)))\n",
    "model.add(LSTM(64, return_sequences=False))\n",
    "model.add(Dense(25))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model part 5 (no activation function)\n",
    "model.fit(np.array(X_train).reshape(-1,5,1), y_train, batch_size =800, epochs=50, verbose=0)\n",
    "\n",
    "#predictions \n",
    "predictions = model.predict(np.array(X_test).reshape(-1,5,1))\n",
    "\n",
    "#calculation of the mean absolute error\n",
    "mean_abs_error = mean_absolute_error(y_test, predictions)\n",
    "mean_abs_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction Using Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating an instance of a Linear Regressor \n",
    "model_lin2 = LinearRegression()\n",
    "\n",
    "#fit the model\n",
    "model_lin2.fit(X_train,y_train)\n",
    "\n",
    "#prediction\n",
    "predict = model_lin2.predict(X_test)\n",
    "\n",
    "#calculation of the mean absolute error\n",
    "mean_abs_error = mean_absolute_error(y_test, predict)\n",
    "mean_abs_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction Using Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating an instance of a Random Forest Regressor \n",
    "model_rf2 = RandomForestRegressor(n_estimators=100, random_state=47)\n",
    "\n",
    "#fit the model with the training data\n",
    "model_rf2.fit(X_train,y_train)\n",
    "\n",
    "#prediction\n",
    "predict2 = model_rf2.predict(X_test)\n",
    "predict2 #view some predictions\n",
    "\n",
    "#calculation of the mean absolute error\n",
    "mean_abs_error2 = mean_absolute_error(y_test, predict2)\n",
    "mean_abs_error2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot showing the prediction and actual values\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(24, 10), dpi=80)\n",
    "axs[0].set_title('Predicted vs actual values distribution')\n",
    "ax1 = sns.kdeplot(data=y_test, color=\"g\", label='Actual values',ax=axs[0])\n",
    "ax2 = sns.kdeplot(data=predict2, color=\"b\", label='Predicted values', ax=ax1)\n",
    "    \n",
    "sns.regplot(x=y_test, y=predict2)\n",
    "plt.title('Predicted vs actual values distribution')\n",
    "plt.xlabel('Stock Price')\n",
    "#plt.legend()\n",
    "ax1.legend()\n",
    "plt.show()\n",
    "plt.close()\n",
    "    \n",
    "print(\"Mean absolute error of {0}: {1}\".format(model_rf2,mean_abs_error2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot showing the prediction and actual values\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(24, 10), dpi=80)\n",
    "axs[0].set_title('Actual values distribution')\n",
    "axs[1].set_title('Predicted values distribution')\n",
    "ax1 = sns.kdeplot(data=y_test, color=\"g\", label='Actual values',ax=axs[0])\n",
    "ax2 = sns.kdeplot(data=predict2, color=\"b\", label='Predicted values', ax=axs[1])\n",
    "\n",
    "ax1.legend()\n",
    "ax2.legend()\n",
    "plt.show()\n",
    "plt.close()\n",
    "    \n",
    "print(\"Mean absolute error of {0}: {1}\".format(model_rf2,mean_abs_error2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above, we can see that the model is trained and evaluated using `RandomForestRegressor`. The predicted and actual adjustable Google stock prices plots look are very similar with a mean absolute error is 0.000824 which is very good. We can also see that all three models perform better with Google than Microsoft stocks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Results\n",
    "\n",
    "### Evaluation and Validation of models\n",
    "From my investigation of three different models, I observed that RandomForestRegressor delivered a much lower mean absolute error (0.0497, 0.000824) than the LSTM (0.0942, 0.00646) or LinearRegression (0.215, 0.167) for Microsoft and Google respectively.  I also observed that tunning the parameters for LSTM (e.g the number of epochs and batch_size) resulted in better prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interesting facts about the project\n",
    "When exploring the data, it was interesting to see how the stock prices of different companies changed due to the pandemic and how the technological companies stock prices bounced back more quickly than the other companies considered. It was also interesting to see how Pfizer stocks improved as the vaccine rollout began.\n",
    "\n",
    "Here are some major highlights from the data exploration section:\n",
    "\n",
    "  1. 2019: Before the pandemic, most of the companies stocks were doing relatively well with Apple and Microsoft taking the lead and Pfizer trailing behind.\n",
    "  2. 2020: On the onset of the pandemic around Spring, there was a fall in stock prices for all the companies, but afterwards the technology companies like Amazon, Apple, Microsoft and Google started to grow again. But companies like Pfizer, Ford and S&P 500 did not do very well especially Ford.\n",
    "  3. 2021: As the vaccine rollout began and the lockdown began to be lifted, there was significant growth in the stock prices of Ford in particular given its very stock prices which was low in 2020 due to the pandemic. Companies like Google and Microsoft,S&P 500 also grew. Overall there was an improvement in the stock prices of all the companies we considered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Difficulties encountered\n",
    "1. Getting the data from yahoo fincance wasn't very obvious. After several research I was able to find an [article](https://towardsdatascience.com/free-stock-data-for-python-using-yahoo-finance-api-9dafd96cad2e) that guided me on how to obtain the data.\n",
    "2. The [Machine Learning for Trading course](https://www.udacity.com/course/machine-learning-for-trading--ud501) was also really helpful to knowing more about financial data and how to handle it as well as knowing where to begin my data exploration.\n",
    "3. In the modelling part (particularly the LSTM), one would have to spend some time tuning the parameters and training it  to get the best results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improvements\n",
    "An improvement to my analysis could be the following:\n",
    "1. Take some significant time to tune the model parameters as well as include more features that might be relevant for stock price prediction.\n",
    "2. Try out more models and see if there might be one with a better performance than the RandomForestRegressor. I only tried three models for simplicity and time constraints. \n",
    "3. Explore other companies stocks to see how well one can predict their stocks prices with different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
